{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manbradcalf/CoLab-Random/blob/main/chr1/Chapter%20I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6147909f-7b77-4bc2-b662-eb001fe1d7fa",
      "metadata": {
        "id": "6147909f-7b77-4bc2-b662-eb001fe1d7fa"
      },
      "source": [
        "# Chapter I\n",
        "\n",
        "This is the code for the chapter I of the book"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ddbbd91-a488-4829-98b3-64f18899c49b",
      "metadata": {
        "id": "2ddbbd91-a488-4829-98b3-64f18899c49b"
      },
      "source": [
        "## How to represent text for AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6b10a40a-3f4b-4711-893b-a96486a43aa0",
      "metadata": {
        "id": "6b10a40a-3f4b-4711-893b-a96486a43aa0"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e953ef4b-eb91-41dd-befc-6ea5d20f1167",
      "metadata": {
        "id": "e953ef4b-eb91-41dd-befc-6ea5d20f1167",
        "outputId": "a2aad15c-b0e9-4c19-9914-c90721abf03e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['a', 'do', 'go', 'or', 'pizzeria', 'prefer', 'restaurant?', 'should', 'to', 'we', 'you']\n",
            "One-Hot Encoding Matrix:\n",
            " [[0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1]\n",
            " [1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "def one_hot_encoding(sentence):\n",
        "    words = sentence.lower().split()\n",
        "    vocabulary = sorted(set(words))\n",
        "    word_to_index = {word: i for i, word in enumerate(vocabulary)}\n",
        "    one_hot_matrix = np.zeros((len(words), len(vocabulary)), dtype=int)\n",
        "    for i, word in enumerate(words):\n",
        "        one_hot_matrix[i, word_to_index[word]] = 1\n",
        "\n",
        "    return one_hot_matrix, vocabulary\n",
        "\n",
        "# Example of usage\n",
        "sentence = \"Should we go to a pizzeria or do you a prefer a restaurant?\"\n",
        "one_hot_matrix, vocabulary = one_hot_encoding(sentence)\n",
        "print(\"Vocabulary:\", vocabulary)\n",
        "print(\"One-Hot Encoding Matrix:\\n\", one_hot_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cb3434e6-e8a5-4a28-a8a3-aef8fa9e3539",
      "metadata": {
        "id": "cb3434e6-e8a5-4a28-a8a3-aef8fa9e3539",
        "outputId": "0e7c3bbb-f3ac-4f66-fde5-1ab70f11ffde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['a', 'awesome', 'awesome?', 'but', 'can', 'do', 'fool', 'good,', 'i', 'is', 'movie', 'neither', 'not', 'only', 'say', 'that', 'this']\n",
            "Bag of Words Matrix:\n",
            " [[0 2 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1]\n",
            " [0 1 0 1 0 1 0 1 1 1 0 1 1 0 1 0 0]\n",
            " [1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0]]\n"
          ]
        }
      ],
      "source": [
        "def bag_of_words(sentences):\n",
        "    \"\"\"\n",
        "    Creates a bag-of-words representation of a list of documents.\n",
        "    \"\"\"\n",
        "    tokenized_sentences = [sentence.lower().split() for sentence in sentences]\n",
        "    flat_words = [word for sublist in tokenized_sentences for word in sublist]\n",
        "    vocabulary = sorted(set(flat_words))\n",
        "    word_to_index = {word: i for i, word in enumerate(vocabulary)}\n",
        "\n",
        "    bow_matrix = np.zeros((len(sentences), len(vocabulary)), dtype=int)\n",
        "    for i, sentence in enumerate(tokenized_sentences):\n",
        "        for word in sentence:\n",
        "            if word in word_to_index:\n",
        "                bow_matrix[i, word_to_index[word]] += 1\n",
        "\n",
        "    return vocabulary, bow_matrix\n",
        "\n",
        "# Example of usage\n",
        "corpus = [\"This movie is awesome awesome\", \"I do not say is good, but neither awesome\",\n",
        "             \"Awesome? Only a fool can say that\"]\n",
        "vocabulary, bow_matrix = bag_of_words(corpus)\n",
        "print(\"Vocabulary:\", vocabulary)\n",
        "print(\"Bag of Words Matrix:\\n\", bow_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f66dbeda-eef2-4cbe-885e-72cd1bc6da8b",
      "metadata": {
        "id": "f66dbeda-eef2-4cbe-885e-72cd1bc6da8b",
        "outputId": "7c6091c4-48ac-4338-aa8c-4fa9862215f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['a', 'awesome', 'awesome?', 'but', 'can', 'do', 'fool', 'good,', 'i', 'is', 'movie', 'neither', 'not', 'only', 'say', 'that', 'this']\n",
            "TF-IDF Matrix:\n",
            " [[0.         0.4        0.         0.         0.         0.\n",
            "  0.         0.         0.         0.2        0.28109303 0.\n",
            "  0.         0.         0.         0.         0.28109303]\n",
            " [0.         0.11111111 0.         0.1561628  0.         0.1561628\n",
            "  0.         0.1561628  0.1561628  0.11111111 0.         0.1561628\n",
            "  0.1561628  0.         0.11111111 0.         0.        ]\n",
            " [0.20078073 0.         0.20078073 0.         0.20078073 0.\n",
            "  0.20078073 0.         0.         0.         0.         0.\n",
            "  0.         0.20078073 0.14285715 0.20078073 0.        ]]\n"
          ]
        }
      ],
      "source": [
        "def compute_tf(sentences):\n",
        "    \"\"\"Compute the term frequency matrix for a list of sentences.\"\"\"\n",
        "    vocabulary = sorted(set(word for sentence in sentences for word in sentence.lower().split()))\n",
        "    word_index = {word: i for i, word in enumerate(vocabulary)}\n",
        "    tf = np.zeros((len(sentences), len(vocabulary)), dtype=np.float32)\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        words = sentence.lower().split()\n",
        "        word_count = len(words)\n",
        "        for word in words:\n",
        "            if word in word_index:\n",
        "                tf[i, word_index[word]] += 1 / word_count\n",
        "    return tf, vocabulary\n",
        "\n",
        "def compute_idf(sentences, vocabulary):\n",
        "    \"\"\"Compute the inverse document frequency for a list of sentences.\"\"\"\n",
        "    num_documents = len(sentences)\n",
        "    idf = np.zeros(len(vocabulary), dtype=np.float32)\n",
        "    word_index = {word: i for i, word in enumerate(vocabulary)}\n",
        "    for word in vocabulary:\n",
        "        df = sum(1 for sentence in sentences if word in sentence.lower().split())\n",
        "        idf[word_index[word]] = np.log(num_documents / (1 + df)) + 1  # Smoothing\n",
        "    return idf\n",
        "\n",
        "def tf_idf(sentences):\n",
        "    \"\"\"Generate a TF-IDF matrix for a list of sentences.\"\"\"\n",
        "    tf, vocabulary = compute_tf(sentences)\n",
        "    idf = compute_idf(sentences, vocabulary)\n",
        "    tf_idf_matrix = tf * idf\n",
        "    return vocabulary, tf_idf_matrix\n",
        "\n",
        "vocabulary, tf_idf_matrix = tf_idf(corpus)\n",
        "print(\"Vocabulary:\", vocabulary)\n",
        "print(\"TF-IDF Matrix:\\n\", tf_idf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08a190e6-707d-4354-974a-0196e1309c4c",
      "metadata": {
        "id": "08a190e6-707d-4354-974a-0196e1309c4c"
      },
      "source": [
        "## Embedding, application, and representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5a7d984f-da22-4ab5-a498-31430b94fadd",
      "metadata": {
        "id": "5a7d984f-da22-4ab5-a498-31430b94fadd",
        "outputId": "0918acbe-b2c2-4c7f-fad0-1d61091e60a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Requirement already satisfied: adjustText in /usr/local/lib/python3.12/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from adjustText) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from adjustText) (3.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from adjustText) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->adjustText) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->adjustText) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->adjustText) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->adjustText) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->adjustText) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->adjustText) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->adjustText) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->adjustText) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->adjustText) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import nltk\n",
        "!pip install gensim\n",
        "from gensim.models import Word2Vec\n",
        "from tqdm import tqdm\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "!pip install adjustText\n",
        "from adjustText import adjust_text\n",
        "from umap import UMAP\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "539e71a5-12cd-438e-b6a0-96741a2dd36b",
      "metadata": {
        "id": "539e71a5-12cd-438e-b6a0-96741a2dd36b",
        "outputId": "92bc5f2a-166d-4abb-ec6b-ae590966c11d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-16 21:07:28--  https://github.com/SalvatoreRa/tutorial/blob/main/datasets/IMDB.zip?raw=true\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/SalvatoreRa/tutorial/raw/refs/heads/main/datasets/IMDB.zip [following]\n",
            "--2025-11-16 21:07:28--  https://github.com/SalvatoreRa/tutorial/raw/refs/heads/main/datasets/IMDB.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SalvatoreRa/tutorial/refs/heads/main/datasets/IMDB.zip [following]\n",
            "--2025-11-16 21:07:28--  https://raw.githubusercontent.com/SalvatoreRa/tutorial/refs/heads/main/datasets/IMDB.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26962657 (26M) [application/zip]\n",
            "Saving to: ‘IMDB.zip?raw=true’\n",
            "\n",
            "IMDB.zip?raw=true   100%[===================>]  25.71M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-11-16 21:07:31 (521 MB/s) - ‘IMDB.zip?raw=true’ saved [26962657/26962657]\n",
            "\n",
            "Archive:  IMDB.zip?raw=true\n",
            "  inflating: IMDB Dataset.csv        \n"
          ]
        }
      ],
      "source": [
        "#this for unzip and read the file\n",
        "!wget https://github.com/SalvatoreRa/tutorial/blob/main/datasets/IMDB.zip?raw=true\n",
        "!unzip IMDB.zip?raw=true\n",
        "df=pd.read_csv(\"IMDB Dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9181f172-4593-47a8-88ae-49983d4711bb",
      "metadata": {
        "id": "9181f172-4593-47a8-88ae-49983d4711bb",
        "outputId": "c59ac3c9-d20e-4b42-d7ee-86c0d0066d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "100%|██████████| 50000/50000 [00:10<00:00, 4750.17it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment  \\\n",
              "0  One of the other reviewers has mentioned that ...  positive   \n",
              "1  A wonderful little production. <br /><br />The...  positive   \n",
              "2  I thought this was a wonderful way to spend ti...  positive   \n",
              "3  Basically there's a family where a little boy ...  negative   \n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
              "\n",
              "                                   reviews_processed  \\\n",
              "0  one of the other reviewers has mentioned that ...   \n",
              "1  wonderful little production the filming techni...   \n",
              "2  thought this was wonderful way to spend time o...   \n",
              "3  basically theres family where little boy jake ...   \n",
              "4  petter matteis love in the time of money is vi...   \n",
              "\n",
              "                                              tokens  \n",
              "0  [one, of, the, other, reviewers, has, mentione...  \n",
              "1  [wonderful, little, production, the, filming, ...  \n",
              "2  [thought, this, was, wonderful, way, to, spend...  \n",
              "3  [basically, theres, family, where, little, boy...  \n",
              "4  [petter, matteis, love, in, the, time, of, mon...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db17f6b7-9f4e-4084-8d0f-ee679663c43f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>reviews_processed</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>one of the other reviewers has mentioned that ...</td>\n",
              "      <td>[one, of, the, other, reviewers, has, mentione...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>wonderful little production the filming techni...</td>\n",
              "      <td>[wonderful, little, production, the, filming, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>thought this was wonderful way to spend time o...</td>\n",
              "      <td>[thought, this, was, wonderful, way, to, spend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>basically theres family where little boy jake ...</td>\n",
              "      <td>[basically, theres, family, where, little, boy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>petter matteis love in the time of money is vi...</td>\n",
              "      <td>[petter, matteis, love, in, the, time, of, mon...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db17f6b7-9f4e-4084-8d0f-ee679663c43f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db17f6b7-9f4e-4084-8d0f-ee679663c43f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db17f6b7-9f4e-4084-8d0f-ee679663c43f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-123710ae-e92b-4138-911a-9bd433579e6b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-123710ae-e92b-4138-911a-9bd433579e6b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-123710ae-e92b-4138-911a-9bd433579e6b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviews_processed\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49580,\n        \"samples\": [\n          \"this movie was modern day scarfaceit had me on my toesthis movie is one of those rare epic films that makes you want sequeli especially liked damian chapa his performance deserved an academy awardwhich he deserved for his performance in blood in blood outthe only thing didnt like was the behind the scenes because it didnt show the intensity that the movie hadand would have like to have seen less narrated scenesbut the movie was great and it is in my top ten movies of all timeplus the acting was great there wasnt bad scene in the moviei loved it jennifer tilly was perfect as well as all of the casti cant see how anyone wouldnt like this movie it was greatdefinitely must see\",\n          \"this is probably one of the best french movies had seen in very long time this pastiche or parody of spy movies is very well made and is going to make you laugh from the beginning to the end some references to todays world are very subtle the whole maroccan context of the movie is to be understood in light of todays french cultureenvironment that said all the jokes and seemingly shocking remarks that could have been understood as such because of this context are permitted and accepted because this is parody was told by my sisters who had already seen this movie that should go too and assured me that was going to have great time and indeed had if you liked the old movies with sean connery and also like movies like airplane or hot shots you will be delighted just hope this movie is released on dvd in the us wait and see\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def preprocessing_reviews(reviews):\n",
        "\n",
        "    \"\"\"\n",
        "    simple preprocessing: splitting on the space and remove word less than 1 chr\n",
        "    \"\"\"\n",
        "\n",
        "    processed_reviews = []\n",
        "\n",
        "    for review in tqdm(reviews):\n",
        "        review = re.sub('<[^>]+>', '', review)\n",
        "        processed = re.sub('[^a-zA-Z ]', '', review)\n",
        "        words = processed.split()\n",
        "        processed_reviews.append(' '.join([word.lower() for word in words if len(word) > 1]))\n",
        "    return processed_reviews\n",
        "\n",
        "df['reviews_processed'] = preprocessing_reviews(df['review'])\n",
        "df['tokens'] = df['reviews_processed'].apply(nltk.word_tokenize)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5e778594-cc87-4293-9afa-8bc792a6b52b",
      "metadata": {
        "id": "5e778594-cc87-4293-9afa-8bc792a6b52b",
        "outputId": "e9b4383f-8d2b-491d-abcc-b28df4f89313",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time needed : 4.29 mins\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "# embedding\n",
        "model = Word2Vec(sentences=df['tokens'].tolist(),\n",
        "                 sg=1,\n",
        "                 vector_size=100,\n",
        "                 window=5,\n",
        "                 workers=4)\n",
        "\n",
        "print(f'Time needed : {(time.time() - start_time) / 60:.2f} mins')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ab78382d-964f-4fa6-8e8d-6581ac22d771",
      "metadata": {
        "id": "ab78382d-964f-4fa6-8e8d-6581ac22d771",
        "outputId": "88cf5af5-da6a-4365-ed7a-6780d6bb5f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Entire set of words in the model\n",
        "all_words = list(model.wv.index_to_key)\n",
        "all_vectors = np.array([model.wv[word] for word in all_words])\n",
        "\n",
        "# Highlighted words and their vectors\n",
        "highlight_words = ['Berlin', 'Paris', 'London','Rome', 'Italy',\n",
        "                   'France', 'Germany', 'England', 'movie', 'production', 'good', 'bad']\n",
        "highs = [w.lower() for w in highlight_words]\n",
        "indices = [all_words.index(word) for word in highs if word in all_words]\n",
        "highlight_vectors = np.array([all_vectors[index] for index in indices])\n",
        "\n",
        "linked = linkage(highlight_vectors, 'ward')\n",
        "\n",
        "plt.figure(figsize=(5, 4))\n",
        "dendrogram(linked,\n",
        "           orientation='top',\n",
        "           labels=highlight_words,\n",
        "           distance_sort='descending',\n",
        "           show_leaf_counts=True)\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Euclidean distances')\n",
        "plt.xticks(rotation=45)\n",
        "plt.savefig('word_dendrogram.jpg', format='jpeg', bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9a4d295b-0bf7-4fa7-b844-7fdb5c176cca",
      "metadata": {
        "id": "9a4d295b-0bf7-4fa7-b844-7fdb5c176cca",
        "outputId": "59213f31-61da-4c9a-b967-e74306239b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2829229194.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Apply t-SNE to the entire set of vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mY_tsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m highlight_words = ['berlin', 'rome', 'London', 'France', 'Germany',\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params_vs_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0mdegrees_of_freedom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m         return self._tsne(\n\u001b[0m\u001b[1;32m   1047\u001b[0m             \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0mdegrees_of_freedom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_iter_without_progress\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_without_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_divergence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopt_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0;31m# Save the final number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, max_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compute_error\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_convergence\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0minc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     error = _barnes_hut_tsne.gradient(\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0mval_P\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mX_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Apply t-SNE to the entire set of vectors\n",
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "Y_tsne = tsne.fit_transform(all_vectors)\n",
        "\n",
        "highlight_words = ['berlin', 'rome', 'London', 'France', 'Germany',\n",
        "                    'movie', 'production', 'mother', 'family']\n",
        "\n",
        "highs = [w.lower() for w in highlight_words]\n",
        "indices = [all_words.index(word) for word in highs if word in all_words]\n",
        "highlight_vectors = np.array([all_vectors[index] for index in indices])\n",
        "Y_highlight = Y_tsne[indices]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "\n",
        "sns.scatterplot(x=Y_tsne[:, 0], y=Y_tsne[:, 1], color=\"lightgrey\", alpha=0.3)\n",
        "\n",
        "# Plot highlighted words\n",
        "palette = sns.color_palette(\"hsv\", len(highlight_words))\n",
        "texts = []\n",
        "for i, word in enumerate(highlight_words):\n",
        "    plt.scatter(Y_highlight[i, 0], Y_highlight[i, 1], color=palette[i], s=100, label=word)\n",
        "    # adjust text\n",
        "    texts.append(plt.text(Y_highlight[i, 0], Y_highlight[i, 1], word, fontsize=12))\n",
        "\n",
        "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='red'))\n",
        "\n",
        "plt.title('t-SNE visualization of Word2Vec embeddings', fontsize=20)\n",
        "plt.xlabel('Component 1')\n",
        "plt.ylabel('Component 2')\n",
        "\n",
        "\n",
        "plt.grid(True)\n",
        "plt.legend(title='Highlighted Words', title_fontsize='13', fontsize='11')\n",
        "plt.savefig('word_tsne.jpg', format='jpeg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cdda4a6-df35-4f03-98c0-5cad29b2b4d9",
      "metadata": {
        "id": "5cdda4a6-df35-4f03-98c0-5cad29b2b4d9"
      },
      "outputs": [],
      "source": [
        "# Apply UMAP to the entire set of vectors\n",
        "umap = UMAP(n_components=2, random_state=42)\n",
        "Y_umap = umap.fit_transform(all_vectors)\n",
        "\n",
        "Y_highlight = Y_umap[indices]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.scatterplot(x=Y_umap[:, 0], y=Y_umap[:, 1], color=\"lightgrey\", alpha=0.3)\n",
        "\n",
        "palette = sns.color_palette(\"hsv\", len(highlight_words))\n",
        "texts = []\n",
        "for i, word in enumerate(highlight_words):\n",
        "    plt.scatter(Y_highlight[i, 0], Y_highlight[i, 1], color=palette[i], s=100, label=word)\n",
        "\n",
        "    texts.append(plt.text(Y_highlight[i, 0], Y_highlight[i, 1], word, fontsize=12))\n",
        "\n",
        "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='red'))\n",
        "\n",
        "plt.title('UMAP visualization of Word2Vec embeddings', fontsize=20)\n",
        "plt.xlabel('Component 1')\n",
        "plt.ylabel('Component 2')\n",
        "\n",
        "\n",
        "plt.grid(True)\n",
        "plt.legend(title='Highlighted Words', title_fontsize='13', fontsize='11')\n",
        "plt.savefig('word_umap.jpg', format='jpeg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e63ba90d-66ba-490f-9b27-666d0656006e",
      "metadata": {
        "id": "e63ba90d-66ba-490f-9b27-666d0656006e"
      },
      "outputs": [],
      "source": [
        "def plot_vectors_and_angle(v1, v2):\n",
        "\n",
        "    dot_product = np.dot(v1, v2)\n",
        "    norm_v1 = np.linalg.norm(v1)\n",
        "    norm_v2 = np.linalg.norm(v2)\n",
        "    cosine_similarity = dot_product / (norm_v1 * norm_v2)\n",
        "    angle_radians = np.arccos(cosine_similarity)\n",
        "    angle_degrees = np.degrees(angle_radians)\n",
        "\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "\n",
        "    ax.quiver(0, 0, v1[0], v1[1], angles='xy', scale_units='xy', scale=1, color='r', label=f\"Vector 1: {v1}\")\n",
        "    ax.quiver(0, 0, v2[0], v2[1], angles='xy', scale_units='xy', scale=1, color='b', label=f\"Vector 2: {v2}\")\n",
        "\n",
        "\n",
        "    start_angle = np.arctan2(v1[1], v1[0])\n",
        "    if np.cross(v1, v2) < 0:\n",
        "        angle_radians = -angle_radians\n",
        "\n",
        "\n",
        "    theta = np.linspace(start_angle, start_angle + angle_radians, 100)\n",
        "    r = 0.5 * min(np.linalg.norm(v1), np.linalg.norm(v2))\n",
        "    x = r * np.cos(theta)\n",
        "    y = r * np.sin(theta)\n",
        "\n",
        "\n",
        "    ax.plot(x, y, linestyle='-', color='green', lw=2)\n",
        "\n",
        "\n",
        "    midpoint = (start_angle + angle_radians / 2)\n",
        "    ax.annotate(r'$\\theta$', xy=(r * np.cos(midpoint), r * np.sin(midpoint)), xytext=(20, 10),\n",
        "                textcoords='offset points', fontsize=16, arrowprops=dict(arrowstyle='->', lw=0.5))\n",
        "\n",
        "\n",
        "    max_range = np.max(np.abs(np.vstack([v1, v2, [x.max(), y.max()]]))) * 1.1  # 10% padding\n",
        "    ax.set_xlim([-max_range, max_range])\n",
        "    ax.set_ylim([-max_range, max_range])\n",
        "\n",
        "\n",
        "    plt.grid(True)\n",
        "    plt.axhline(0, color='black', linewidth=0.5)\n",
        "    plt.axvline(0, color='black', linewidth=0.5)\n",
        "    plt.title(f'Angle between vectors: {angle_degrees:.2f} degrees')\n",
        "    plt.suptitle(f'Similarity between vectors: {cosine_similarity:.2f}', fontsize=10, y=.95)\n",
        "    plt.xlabel('Component 1')\n",
        "    plt.ylabel('Component 2')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.savefig('cosine_similarity.jpg', format='jpeg', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    return cosine_similarity, angle_degrees\n",
        "\n",
        "# Example usage\n",
        "v1 = np.array([2, 3])\n",
        "v2 = np.array([-1, 2])\n",
        "cos_sim, angle = plot_vectors_and_angle(v1, v2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11858cc1-a482-4bbc-bb1f-deb25448e319",
      "metadata": {
        "id": "11858cc1-a482-4bbc-bb1f-deb25448e319"
      },
      "outputs": [],
      "source": [
        "word_1 = \"good\"\n",
        "syn = \"great\"\n",
        "ant = \"bad\"\n",
        "most_sim =model.wv.most_similar(\"good\")\n",
        "print(\"Top 3 most simalr words to {} are :{}\".format(word_1, most_sim[:3]))\n",
        "\n",
        "synonyms_dist = model.wv.distance(word_1, syn)\n",
        "antonyms_dist = model.wv.distance(word_1, ant)\n",
        "print(\"Synonyms {}, {} have cosine distance: {}\".format(word_1, syn, synonyms_dist))\n",
        "print(\"Antonyms {}, {} have cosine distance: {}\".format(word_1, ant, antonyms_dist))\n",
        "a = 'king'\n",
        "a_star = 'man'\n",
        "b = 'woman'\n",
        "b_star= model.wv.most_similar(positive=[a, b], negative=[a_star])\n",
        "print(\"{} is to {} as {} is to: {} \".format(a, a_star, b, b_star[0][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e32d319-8ee4-4bff-907a-96e2f9a623fc",
      "metadata": {
        "id": "2e32d319-8ee4-4bff-907a-96e2f9a623fc"
      },
      "source": [
        "# RNN, LSTM, GRU, CNN for text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18e3d509-fac6-47f3-8c35-20a5e12c7bd2",
      "metadata": {
        "id": "18e3d509-fac6-47f3-8c35-20a5e12c7bd2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "117a8c1d-b7b8-4e4f-b8cc-105ecbdcea4c",
      "metadata": {
        "id": "117a8c1d-b7b8-4e4f-b8cc-105ecbdcea4c"
      },
      "outputs": [],
      "source": [
        "array = np.random.random((10, 5, 3))\n",
        "\n",
        "data_tensor = torch.tensor(array, dtype=torch.float32)\n",
        "RNN = nn.RNN(input_size=3, hidden_size=10,\n",
        "                          num_layers=1, batch_first=True)\n",
        "output, hidden = RNN(data_tensor)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "644e7d7c-6765-4a60-a4a5-376f17edc665",
      "metadata": {
        "id": "644e7d7c-6765-4a60-a4a5-376f17edc665"
      },
      "outputs": [],
      "source": [
        "data_tensor = torch.tensor(np.random.random((10, 5, 3)), dtype=torch.float32)\n",
        "LSTM =nn.LSTM(input_size=3, hidden_size=10,\n",
        "                    num_layers=1, batch_first=True)\n",
        "output, (hidden, cell) = LSTM(data_tensor)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a9d409-0a35-418f-989e-30b3ddb2c26e",
      "metadata": {
        "id": "a5a9d409-0a35-418f-989e-30b3ddb2c26e"
      },
      "outputs": [],
      "source": [
        "data_tensor = torch.tensor(np.random.random((10, 5, 3)), dtype=torch.float32)\n",
        "GRU =nn.GRU(input_size=3, hidden_size=10,\n",
        "                    num_layers=1, batch_first=True)\n",
        "output, hidden = GRU(data_tensor)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb91f421-e1f9-4fce-a612-af4bbda84ea2",
      "metadata": {
        "id": "bb91f421-e1f9-4fce-a612-af4bbda84ea2"
      },
      "outputs": [],
      "source": [
        "data_tensor = torch.tensor(np.random.random((10, 5, 3)), dtype=torch.float32)\n",
        "Conv1d = nn.Conv1d(in_channels=5, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "output = Conv1d(data_tensor)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d285e13-1b67-4310-8de8-9523094d3f44",
      "metadata": {
        "id": "8d285e13-1b67-4310-8de8-9523094d3f44"
      },
      "source": [
        "# Classify review with deep learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a2f9f3e-c998-47f0-ac32-49e0a70167fe",
      "metadata": {
        "id": "0a2f9f3e-c998-47f0-ac32-49e0a70167fe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.manifold import TSNE\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# Check if we GPU available\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6802968-c646-4e70-a848-cd1a940be983",
      "metadata": {
        "id": "d6802968-c646-4e70-a848-cd1a940be983"
      },
      "outputs": [],
      "source": [
        "#this for unzip and read the file\n",
        "try:\n",
        "    df=pd.read_csv(\"IMDB Dataset.csv\")\n",
        "except:\n",
        "    !wget https://github.com/SalvatoreRa/tutorial/blob/main/datasets/IMDB.zip?raw=true\n",
        "    !unzip IMDB.zip?raw=true\n",
        "\n",
        "df['sentiment_encoded'] = np.where(df['sentiment']=='positive',0,1)\n",
        "X,y = df['review'].values, df['sentiment_encoded'].values\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y, test_size=.2)\n",
        "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,stratify=y_train, test_size=.1)\n",
        "y_train, y_val, y_test = np.array(y_train), np.array(y_val), np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a23ff15-11e3-4dc7-90c5-5bd621dcbf11",
      "metadata": {
        "id": "0a23ff15-11e3-4dc7-90c5-5bd621dcbf11"
      },
      "outputs": [],
      "source": [
        "def generate_wordclouds(df):\n",
        "    '''\n",
        "    Generate two word clouds from the 50 most frequent words in the list of positive and negative reviews respectively.\n",
        "\n",
        "    '''\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Separating reviews by sentiment\n",
        "    positive_reviews = df[df['sentiment'] == 'positive']['review']\n",
        "    negative_reviews = df[df['sentiment'] == 'negative']['review']\n",
        "\n",
        "\n",
        "    def get_words(reviews):\n",
        "        all_words = []\n",
        "        for review in reviews:\n",
        "            review = re.sub(r\"[^\\w\\s]\", '', review)\n",
        "            review = re.sub(r\"\\d\", '', review)\n",
        "            words = review.split()\n",
        "            filtered_words = [word for word in words if word not in stop_words and len(word) > 1]\n",
        "            all_words.extend(filtered_words)\n",
        "        return all_words\n",
        "\n",
        "\n",
        "    positive_words = get_words(positive_reviews)\n",
        "    negative_words = get_words(negative_reviews)\n",
        "\n",
        "\n",
        "    positive_counts = Counter(positive_words)\n",
        "    negative_counts = Counter(negative_words)\n",
        "\n",
        "\n",
        "    positive_wordcloud = WordCloud(\n",
        "        width=400,\n",
        "        height=400,\n",
        "        max_words=200,\n",
        "        max_font_size=100,\n",
        "        background_color='white',\n",
        "        color_func=lambda *args, **kwargs: \"green\"\n",
        "    ).generate_from_frequencies(positive_counts)\n",
        "\n",
        "    negative_wordcloud = WordCloud(\n",
        "        width=400,\n",
        "        height=400,\n",
        "        max_words=200,\n",
        "        max_font_size=100,\n",
        "        background_color='white',\n",
        "        color_func=lambda *args, **kwargs: \"red\"\n",
        "    ).generate_from_frequencies(negative_counts)\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(positive_wordcloud, interpolation='bilinear')\n",
        "    plt.title('Positive Reviews')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(negative_wordcloud, interpolation='bilinear')\n",
        "    plt.title('Negative Reviews')\n",
        "    plt.axis(\"off\")\n",
        "    plt.savefig('word_clouds.jpg', format='jpeg', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "generate_wordclouds(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b963cd8-8ba1-46cc-9019-2f05b04166fe",
      "metadata": {
        "id": "2b963cd8-8ba1-46cc-9019-2f05b04166fe"
      },
      "outputs": [],
      "source": [
        "def plot_review_length_by_sentiment(df):\n",
        "    '''\n",
        "    Plots histograms of the number of words per review for positive and negative reviews with summary statistics.\n",
        "\n",
        "    '''\n",
        "\n",
        "    positive_reviews = df[df['sentiment'] == 'positive']['review']\n",
        "    negative_reviews = df[df['sentiment'] == 'negative']['review']\n",
        "\n",
        "\n",
        "    def get_review_lengths(reviews):\n",
        "        return [len(review.split()) for review in reviews]\n",
        "\n",
        "\n",
        "    positive_lengths = get_review_lengths(positive_reviews)\n",
        "    negative_lengths = get_review_lengths(negative_reviews)\n",
        "\n",
        "\n",
        "    def get_summary_stats(lengths):\n",
        "        return {\n",
        "            'min': np.min(lengths),\n",
        "            'avg': np.mean(lengths),\n",
        "            'median': np.median(lengths),\n",
        "            'max': np.max(lengths)\n",
        "        }\n",
        "\n",
        "    pos_stats = get_summary_stats(positive_lengths)\n",
        "    neg_stats = get_summary_stats(negative_lengths)\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot for positive reviews\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(positive_lengths, bins=30, color='green', edgecolor='black', alpha=0.7)\n",
        "    plt.title('Word Distribution for Positive Reviews')\n",
        "    plt.xlabel('Number of Words')\n",
        "    plt.ylabel('Number of Reviews')\n",
        "    plt.grid(True)\n",
        "    stats_text = f\"Min: {pos_stats['min']}\\nAvg: {pos_stats['avg']:.2f}\\nMedian: {pos_stats['median']}\\nMax: {pos_stats['max']}\"\n",
        "    plt.text(0.95, 0.95, stats_text, transform=plt.gca().transAxes, fontsize=10, verticalalignment='top', horizontalalignment='right', bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='wheat', alpha=0.5))\n",
        "\n",
        "    # Plot for negative reviews\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(negative_lengths, bins=30, color='red', edgecolor='black', alpha=0.7)\n",
        "    plt.title('Word Distribution for Negative Reviews')\n",
        "    plt.xlabel('Number of Words')\n",
        "    plt.ylabel('Number of Reviews')\n",
        "    plt.grid(True)\n",
        "    stats_text = f\"Min: {neg_stats['min']}\\nAvg: {neg_stats['avg']:.2f}\\nMedian: {neg_stats['median']}\\nMax: {neg_stats['max']}\"\n",
        "    plt.text(0.95, 0.95, stats_text, transform=plt.gca().transAxes, fontsize=10, verticalalignment='top', horizontalalignment='right', bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='wheat', alpha=0.5))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('review_length.jpg', format='jpeg', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "plot_review_length_by_sentiment(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "077a8e8f-2a28-4267-a75e-6d43fa6518c8",
      "metadata": {
        "id": "077a8e8f-2a28-4267-a75e-6d43fa6518c8"
      },
      "outputs": [],
      "source": [
        "def preprocess_review(review):\n",
        "    '''\n",
        "    Cleaning of the review: remove non-alphanumeric characters, collapse whitespace, and remove digits.\n",
        "    '''\n",
        "    review = re.sub(r\"[^\\w\\s]\", ' ', review)  # Replace non-word characters with space\n",
        "    review = re.sub(r\"\\s+\", ' ', review)      # Replace multiple spaces with a single space\n",
        "    review = re.sub(r\"\\d\", '', review)        # Remove digits\n",
        "    return review.strip().lower()\n",
        "\n",
        "def tokenize_reviews(x_train, x_val, x_test):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # tokenize and clean list of reviews\n",
        "    def tokenize_and_filter(reviews):\n",
        "        word_list = []\n",
        "        for review in reviews:\n",
        "            words = word_tokenize(preprocess_review(review))\n",
        "            filtered_words = [word for word in words if word not in stop_words and len(word) > 1]\n",
        "            word_list.extend(filtered_words)\n",
        "        return word_list\n",
        "\n",
        "    # Create a corpus\n",
        "    corpus = Counter(tokenize_and_filter(x_train))\n",
        "    # Select the 1000 most common words\n",
        "    vocab = {word: i+1 for i, word in enumerate([word for word, freq in corpus.most_common(1000)])}\n",
        "\n",
        "    # convert reviews into sequences of indices\n",
        "    def vectorize_reviews(reviews):\n",
        "        vectorized = []\n",
        "        for review in reviews:\n",
        "            tokenized = word_tokenize(preprocess_review(review))\n",
        "            indexed = [vocab[word] for word in tokenized if word in vocab]\n",
        "            vectorized.append(indexed)\n",
        "        return vectorized\n",
        "\n",
        "    _x_train = vectorize_reviews(x_train)\n",
        "    _x_val = vectorize_reviews(x_val)\n",
        "    _x_test = vectorize_reviews(x_test)\n",
        "\n",
        "    return _x_train, _x_val, _x_test, vocab\n",
        "\n",
        "\n",
        "x_train, x_val, x_test, vocab = tokenize_reviews(x_train, x_val, x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0670aa4b-555f-4927-be47-3be9fed927c9",
      "metadata": {
        "id": "0670aa4b-555f-4927-be47-3be9fed927c9"
      },
      "outputs": [],
      "source": [
        "def plot_review_length_distribution(tokenized_reviews):\n",
        "    '''\n",
        "    Plots a histogram of the lengths of tokenized reviews and includes a box with summary statistics.\n",
        "\n",
        "    '''\n",
        "\n",
        "    review_lengths = [len(review) for review in tokenized_reviews]\n",
        "\n",
        "    # Calculate summary statistics\n",
        "    min_length = np.min(review_lengths)\n",
        "    avg_length = np.mean(review_lengths)\n",
        "    median_length = np.median(review_lengths)\n",
        "    max_length = np.max(review_lengths)\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(review_lengths, bins=30, color='blue', edgecolor='black', alpha=0.7)\n",
        "    plt.title('Distribution of Review Lengths')\n",
        "    plt.xlabel('Number of Tokens')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "\n",
        "\n",
        "    stats_text = f'Min Length: {min_length}\\nAverage Length: {avg_length:.2f}\\nMedian Length: {median_length}\\nMax Length: {max_length}'\n",
        "    plt.gca().text(0.95, 0.95, stats_text, transform=plt.gca().transAxes, fontsize=10, verticalalignment='top', horizontalalignment='right', bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='wheat', alpha=0.5))\n",
        "    plt.savefig('review_length_after_tokenization.jpg', format='jpeg', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "plot_review_length_distribution(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89f27e53-73ad-43f2-bf88-4825e376a945",
      "metadata": {
        "id": "89f27e53-73ad-43f2-bf88-4825e376a945"
      },
      "outputs": [],
      "source": [
        "def padding_(reviews, max_seq):\n",
        "    features = np.zeros((len(reviews), max_seq),dtype=int)\n",
        "    for ii, review in enumerate(reviews):\n",
        "        if len(review) != 0:\n",
        "            features[ii, -len(review):] = np.array(review)[:max_seq]\n",
        "    return np.array(features)\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(padding_(x_train,500)), torch.from_numpy(y_train))\n",
        "valid_data = TensorDataset(torch.from_numpy(padding_(x_val,500)), torch.from_numpy(y_val))\n",
        "test_data = TensorDataset(torch.from_numpy(padding_(x_test,500)), torch.from_numpy(y_test))\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=50)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=50)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e98eb1bd-91c2-47c7-9319-aabe69a04f02",
      "metadata": {
        "id": "e98eb1bd-91c2-47c7-9319-aabe69a04f02"
      },
      "outputs": [],
      "source": [
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, no_layers, vocab_size, hidden_dim, embedding_dim, drop_prob=0.5):\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.no_layers = no_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.GRU(input_size=embedding_dim, hidden_size=self.hidden_dim,\n",
        "                          num_layers=no_layers, batch_first=True)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        batch_size = x.size(0)\n",
        "        embeds = self.embedding(x)\n",
        "        rnn_out, hidden = self.rnn(embeds, hidden)\n",
        "        rnn_out = rnn_out.contiguous().view(-1, self.hidden_dim)\n",
        "        out = self.dropout(rnn_out)\n",
        "        sig_out = self.sig(out)\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1]\n",
        "        return sig_out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "\n",
        "        h0 = torch.zeros((self.no_layers, batch_size, self.hidden_dim)).to(device)\n",
        "        return h0\n",
        "\n",
        "# Hyperparameters\n",
        "no_layers = 3\n",
        "vocab_size = len(vocab) + 1\n",
        "embedding_dim = 300\n",
        "output_dim = 1\n",
        "hidden_dim = 256\n",
        "\n",
        "# Initialize the model\n",
        "model = SentimentRNN(no_layers, vocab_size, hidden_dim, embedding_dim, drop_prob=0.5)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a9a8a67-45c1-456a-8d2e-6fda0ebd11b5",
      "metadata": {
        "id": "1a9a8a67-45c1-456a-8d2e-6fda0ebd11b5"
      },
      "outputs": [],
      "source": [
        "x_train_tsne = padding_(x_train,500)\n",
        "x_train_tsne = x_train_tsne[:1000,:]\n",
        "y_train_tsne= y_train[:1000]\n",
        "\n",
        "def plot_embeddings(x_train, y_train, model, device, batch_size=50):\n",
        "    model.eval()\n",
        "    embeddings_list = []\n",
        "\n",
        "    # Create a DataLoader to handle the x_train data in batches\n",
        "    train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(x_train),\n",
        "                               torch.from_numpy(y_train))\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients\n",
        "        for x_batch, _ in train_loader:\n",
        "            x_batch = x_batch.to(device)\n",
        "            hidden = model.init_hidden(x_batch.size(0))\n",
        "\n",
        "            # Feed forward through the model to get to the embeddings layer\n",
        "            embeds = model.embedding(x_batch)\n",
        "            rnn_out, hidden = model.rnn(embeds, hidden)\n",
        "            rnn_out = rnn_out.contiguous().view(-1, model.hidden_dim)  # Flatten the output\n",
        "            out = model.dropout(rnn_out)\n",
        "            linear_output = model.fc(out)\n",
        "\n",
        "            embeddings_list.append(linear_output.cpu())  # Store CPU data\n",
        "\n",
        "    # Concatenate all batch embeddings into a single matrix\n",
        "    all_embeddings = torch.cat(embeddings_list, dim=0)\n",
        "\n",
        "    all_embeddings = all_embeddings.view(-1, 500)\n",
        "\n",
        "    # Reduce dimensions to 2D using t-SNE for visualization\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    embeddings_2d = tsne.fit_transform(all_embeddings.numpy())\n",
        "\n",
        "    df = pd.DataFrame(data=embeddings_2d, columns=['TSNE-1', 'TSNE-2'])\n",
        "    df['label'] = y_train\n",
        "    custom_palette = {0: 'green', 1: 'red'}\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    scatter = sns.scatterplot(data=df, x='TSNE-1', y='TSNE-2', hue='label', palette=custom_palette , s=60, alpha=0.6)\n",
        "    plt.title('2D t-SNE Visualization of Sentence Embeddings')\n",
        "    plt.xlabel('t-SNE dimension 1')\n",
        "    plt.ylabel('t-SNE dimension 2')\n",
        "    plt.legend(title='Label', bbox_to_anchor=(1.05, 1), loc=2)\n",
        "    plt.savefig('tsne_model_untrained_projection.jpg', format='jpeg', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_embeddings(x_train_tsne, y_train_tsne, model, device, batch_size=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "918ed4b6-7677-4918-beb6-3e9a827b0423",
      "metadata": {
        "id": "918ed4b6-7677-4918-beb6-3e9a827b0423"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "lr = 0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "def acc(pred, label):\n",
        "    \"\"\"Calculate accuracy by comparing predicted labels with true labels.\"\"\"\n",
        "    pred = torch.round(pred.squeeze())\n",
        "    return torch.sum(pred == label.squeeze()).item()\n",
        "\n",
        "clip = 5\n",
        "epochs = 5\n",
        "valid_loss_min = np.inf\n",
        "\n",
        "\n",
        "epoch_tr_loss, epoch_vl_loss = [], []\n",
        "epoch_tr_acc, epoch_vl_acc = [], []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_losses = []\n",
        "    train_acc = 0.0\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    # Initialize hidden state\n",
        "    h = model.init_hidden(50)\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Detach hidden states\n",
        "        h = h.data\n",
        "\n",
        "        model.zero_grad()\n",
        "        output, h = model(inputs, h)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = acc(output, labels)\n",
        "        train_acc += accuracy\n",
        "\n",
        "        # Clip gradients to prevent exploding gradient issues in RNNs\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation phase\n",
        "    val_losses = []\n",
        "    val_acc = 0.0\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_h = model.init_hidden(50)\n",
        "\n",
        "    for inputs, labels in valid_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Detach hidden states\n",
        "        val_h = val_h.data\n",
        "\n",
        "        output, val_h = model(inputs, val_h)\n",
        "        val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "        val_losses.append(val_loss.item())\n",
        "\n",
        "        accuracy = acc(output, labels)\n",
        "        val_acc += accuracy\n",
        "\n",
        "    epoch_train_loss = np.mean(train_losses)\n",
        "    epoch_val_loss = np.mean(val_losses)\n",
        "    epoch_train_acc = train_acc / len(train_loader.dataset)\n",
        "    epoch_val_acc = val_acc / len(valid_loader.dataset)\n",
        "\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "\n",
        "    print(f'Epoch {epoch+1}')\n",
        "    print(f'Train Loss: {epoch_train_loss} Val Loss: {epoch_val_loss}')\n",
        "    print(f'Train Accuracy: {epoch_train_acc * 100}% Val Accuracy: {epoch_val_acc * 100}%')\n",
        "    print(' ')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "043bc6d4-1b36-4c93-8112-ee4d9cbad9e4",
      "metadata": {
        "id": "043bc6d4-1b36-4c93-8112-ee4d9cbad9e4"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (20, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch_tr_acc, label='Train Acc')\n",
        "plt.plot(epoch_vl_acc, label='Validation Acc')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch_tr_loss, label='Train loss')\n",
        "plt.plot(epoch_vl_loss, label='Validation loss')\n",
        "plt.title(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig('accuracy_and_loss.jpg', format='jpeg', bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b620ca16-a518-458a-9ed5-bd82d7dbef2b",
      "metadata": {
        "id": "b620ca16-a518-458a-9ed5-bd82d7dbef2b"
      },
      "outputs": [],
      "source": [
        "def predict_batch(model, data_loader, device):\n",
        "    \"\"\"Predict output for a batch of data using the RNN model.\"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            batch_size = inputs.size(0)\n",
        "\n",
        "            hidden = model.init_hidden(batch_size).to(device)\n",
        "\n",
        "            output, _ = model(inputs, hidden)\n",
        "\n",
        "            predicted_probs = torch.sigmoid(output)\n",
        "            predicted_labels = (predicted_probs > 0.60).float()\n",
        "\n",
        "            predictions.extend(predicted_labels.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return predictions, true_labels, predicted_probs, labels\n",
        "\n",
        "\n",
        "predictions, true_labels, predicted_probs, labels = predict_batch(model, test_loader, device)\n",
        "print(f'Accuracy on test set: {accuracy_score(true_labels, predictions)}')\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig('confusion_matrix.jpg', format='jpeg', bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9de72f16-2596-4314-a18e-a9d5d776ae6d",
      "metadata": {
        "id": "9de72f16-2596-4314-a18e-a9d5d776ae6d"
      },
      "outputs": [],
      "source": [
        "plot_embeddings(x_train_tsne, y_train_tsne, model, device, batch_size=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc3a00fd-1260-464c-9fdd-db705d273f33",
      "metadata": {
        "id": "dc3a00fd-1260-464c-9fdd-db705d273f33"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}